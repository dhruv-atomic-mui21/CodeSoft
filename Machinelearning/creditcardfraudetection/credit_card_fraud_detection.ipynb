{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection\n",
    "This notebook covers the task of detecting fraudulent credit card transactions.\n",
    "We will use the popular Credit Card Fraud Detection dataset from Kaggle.\n",
    "The notebook includes dataset download, preprocessing, model training, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "!pip install -q pandas scikit-learn numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "dataset_url = 'https://storage.googleapis.com/download.tensorflow.org/data/creditcard.csv'\n",
    "dataset_path = 'creditcard.csv'\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "    print('Downloading dataset...')\n",
    "    urllib.request.urlretrieve(dataset_url, dataset_path)\n",
    "    print('Download complete.')\n",
    "else:\n",
    "    print('Dataset already exists.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(dataset_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "- The dataset is highly imbalanced.\n",
    "- We will use undersampling to balance the classes for training.\n",
    "- Features are already scaled except for 'Amount'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "# Scale 'Amount' feature\n",
    "scaler = StandardScaler()\n",
    "X['Amount'] = scaler.fit_transform(X['Amount'].values.reshape(-1,1))\n",
    "\n",
    "# Undersample majority class\n",
    "fraud = df[df['Class'] == 1]\n",
    "non_fraud = df[df['Class'] == 0].sample(n=len(fraud), random_state=42)\n",
    "df_balanced = pd.concat([fraud, non_fraud])\n",
    "\n",
    "X_balanced = df_balanced.drop('Class', axis=1)\n",
    "y_balanced = df_balanced['Class']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "We will train a Random Forest classifier to detect fraud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('\\nClassification Report:\\n', classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
